{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.....\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, LSTM, Dropout, Embedding, Activation\n",
    "from keras.layers import concatenate, BatchNormalization, Input\n",
    "from keras.layers.merge import add\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import string\n",
    "import time\n",
    "print(\"Running.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
      "1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
      "1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
      "1000268201_693b08cb0e.jpg#3\tA little girl climbing the stairs to her playhouse .\n",
      "1000268201_693b08cb0e.jpg#4\tA little girl in a pink dress going into a wooden cabin .\n",
      "1001773457_577c3a7d70.jpg#0\tA black dog and a spotted dog are fighting\n",
      "1001773457_577c3a7\n"
     ]
    }
   ],
   "source": [
    "token_path = '/kaggle/input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr8k.token.txt'\n",
    "text = open(token_path, 'r', encoding = 'utf-8').read()\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 8092\n"
     ]
    }
   ],
   "source": [
    "def load_description(text):\n",
    "    mapping = dict()\n",
    "    for line in text.split(\"\\n\"):\n",
    "        token = line.split(\"\\t\")\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        img_id = token[0].split('.')[0]\n",
    "        img_des = token[1]\n",
    "        if img_id not in mapping:\n",
    "            mapping[img_id] = list()\n",
    "        mapping[img_id].append(img_des)\n",
    "    return mapping\n",
    "\n",
    "descriptions = load_description(text)\n",
    "print(\"Number of items: \" + str(len(descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
       " 'A girl going into a wooden building .',\n",
       " 'A little girl climbing into a wooden playhouse .',\n",
       " 'A little girl climbing the stairs to her playhouse .',\n",
       " 'A little girl in a pink dress going into a wooden cabin .']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['child in pink dress is climbing up set of stairs in an entry way',\n",
       " 'girl going into wooden building',\n",
       " 'little girl climbing into wooden playhouse',\n",
       " 'little girl climbing the stairs to her playhouse',\n",
       " 'little girl in pink dress going into wooden cabin']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_description(desc):\n",
    "    for key, des_list in desc.items():\n",
    "        for i in range(len(des_list)):\n",
    "            caption = des_list[i]\n",
    "            caption = [ch for ch in caption if ch not in string.punctuation]\n",
    "            caption = ''.join(caption)\n",
    "            caption = caption.split(' ')\n",
    "            caption = [word.lower() for word in caption if len(word)>1 and word.isalpha()]\n",
    "            caption = ' '.join(caption)\n",
    "            des_list[i] = caption\n",
    "\n",
    "clean_description(descriptions)\n",
    "descriptions['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8763"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_vocab(desc):\n",
    "    words = set()\n",
    "    for key in desc.keys():\n",
    "        for line in desc[key]:\n",
    "            words.update(line.split())\n",
    "    return words\n",
    "vocab = to_vocab(descriptions)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "images = '/kaggle/input/flickr8k/flickr_data/Flickr_Data/Images/'\n",
    "# Create a list of all image names in the directory\n",
    "img = glob.glob(images + '*.jpg')\n",
    "len(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/kaggle/input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.trainImages.txt'\n",
    "train_images = open(train_path, 'r', encoding = 'utf-8').read().split(\"\\n\")\n",
    "train_img = []\n",
    "\n",
    "for im in img:\n",
    "    if(im[len(images):] in train_images):\n",
    "        train_img.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = '/kaggle/input/flickr8k/flickr_data/Flickr_Data/Flickr_TextData/Flickr_8k.testImages.txt'\n",
    "test_images = open(test_path, 'r', encoding = 'utf-8').read().split(\"\\n\")\n",
    "test_img = []\n",
    "\n",
    "for im in img:\n",
    "    if(im[len(images): ] in test_images):\n",
    "        test_img.append(im)\n",
    "len(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptions: train=6000\n"
     ]
    }
   ],
   "source": [
    "#load descriptions of train and test set separately\n",
    "def load_clean_descriptions(des, dataset):\n",
    "    dataset_des = dict()\n",
    "    for key, des_list in des.items():\n",
    "        if key+'.jpg' in dataset:\n",
    "            if key not in dataset_des:\n",
    "                dataset_des[key] = list()\n",
    "            for line in des_list:\n",
    "                desc = 'startseq ' + line + ' endseq'\n",
    "                dataset_des[key].append(desc)\n",
    "    return dataset_des\n",
    "\n",
    "train_descriptions = load_clean_descriptions(descriptions, train_images)\n",
    "print('Descriptions: train=%d' % len(train_descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_descriptions['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "def preprocess_img(img_path):\n",
    "    #inception v3 excepts img in 299*299\n",
    "    img = load_img(img_path, target_size = (299, 299))\n",
    "    x = img_to_array(img)\n",
    "    # Add one more dimension\n",
    "    x = np.expand_dims(x, axis = 0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my-cap.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
